{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_label(data):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in data:\n",
    "        train_x.append(i[1:])\n",
    "        train_y.append([i[0]])\n",
    "        \n",
    "    return train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titanic_data.csv','r') as file:\n",
    "    temp = csv.reader(file)\n",
    "    data = list(temp)\n",
    "\n",
    "header = data[0]\n",
    "data = data[1:]\n",
    "for i in range(len(data)):\n",
    "    row_len = len(data[0])\n",
    "    for j in range(row_len):\n",
    "        data[i][j] = float(data[i][j])\n",
    "    \n",
    "train_x, train_y = split_train_label(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert all features into binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used average as the criteria to change the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.305524239007892, 0.35400225479143177, 29.471443066516347, 0.5253664036076663, 0.3833145434047351, 32.30542018038328]\n"
     ]
    }
   ],
   "source": [
    "#binary conversion\n",
    "binary_avg = []\n",
    "for i in range(len(header[1:])):\n",
    "    total = 0\n",
    "    avg = 0\n",
    "    for j in train_x:\n",
    "        total += j[i]  \n",
    "    avg = total/len(train_x)      \n",
    "    binary_avg.append(avg)\n",
    "    \n",
    "for i in range(len(train_x)):\n",
    "    for j in range(len(train_x[0])):\n",
    "        if train_x[i][j] >= binary_avg[j]:\n",
    "            train_x[i][j] = 1.0\n",
    "        else:\n",
    "            train_x[i][j] = 0.0\n",
    "            \n",
    "print(binary_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self,train_x,train_y,k_parameter = 10): # input can be k\n",
    "        self.train_x = np.array(train_x)\n",
    "        self.train_y = np.array(train_y)\n",
    "        self.k_parameter = k_parameter\n",
    "    def predict(self,test_x):\n",
    "        test_x = np.array(copy.deepcopy(test_x))\n",
    "        all_distance = []\n",
    "        for idx in range(len(self.train_x)):\n",
    "            single_train_x = self.train_x[idx]\n",
    "            difference = np.subtract(single_train_x,test_x)\n",
    "            distance = 0\n",
    "            for single_error in difference:\n",
    "                distance += abs(single_error)\n",
    "            all_distance.append((idx,distance))\n",
    "        all_distance = sorted(all_distance, key = self.get_difference)\n",
    "        prediction = sum(self.train_y[x[0]] for x in all_distance[:self.k_parameter])/self.k_parameter\n",
    "        \n",
    "        return prediction\n",
    "    def get_difference(self,distance_element):\n",
    "        return distance_element[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = KNN(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict([0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([0.5]), array([0.33333333]), array([0.25]), array([0.2]), array([0.3]), array([0.25]), array([0.26]), array([0.3]), array([0.29])]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in [1,2,3,4,5,10,20,50,100,200]:\n",
    "    predictor = KNN(train_x,train_y,k_parameter = i)\n",
    "    result.append(predictor.predict([0,0,0,0,0,1]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(np.array([0,1,3]),np.array([0,1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titanic_data.csv','r') as file:\n",
    "    temp = csv.reader(file)\n",
    "    data = list(temp)\n",
    "\n",
    "header = data[0]\n",
    "data = data[1:]\n",
    "for i in range(len(data)):\n",
    "    row_len = len(data[0])\n",
    "    for j in range(row_len):\n",
    "        data[i][j] = float(data[i][j])\n",
    "    \n",
    "train_x, train_y = split_train_label(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self,train_x,train_y):\n",
    "        self.train_x = np.array(train_x)\n",
    "        self.train_y = np.array(train_y)\n",
    "    def normal_pdf(self,average,variance,test_value):\n",
    "        likelihood = 1/(np.sqrt(2 * np.pi * variance)) * np.exp( - (test_value - average)**2 / (2 * variance))\n",
    "        return(likelihood)\n",
    "    def predict(self,test_x):\n",
    "        test_x = np.array(copy.deepcopy(test_x))\n",
    "        # divide data into two class\n",
    "        total_class = [[],[]]\n",
    "    \n",
    "        for i in range(len(self.train_x)):\n",
    "            if self.train_y[i] == 0:\n",
    "                total_class[0].append(self.train_x[i])\n",
    "            elif self.train_y[i] == 1:\n",
    "                total_class[1].append(self.train_x[i])              \n",
    "        #calculate class 0 posterior\n",
    "        class_probability = [0,0]\n",
    "        for class_idx in range(2): # go over all class\n",
    "            p_y = len(total_class[class_idx])/(len(total_class[0])+len(total_class[1]))\n",
    "            for feature in range(len(self.train_x[0])):\n",
    "                if feature == 0: # pclass multinomial\n",
    "                    count = 0\n",
    "                    for i in total_class[class_idx]:\n",
    "                        if i[feature] == test_x[feature]:\n",
    "                            count += 1\n",
    "                    print(feature,(count+1)/(len(total_class[class_idx])+3))\n",
    "                    p_y = p_y * (count+1)/(len(total_class[class_idx])+3)\n",
    "                elif feature == 1: # gender binomial\n",
    "                    count = 0\n",
    "                    for i in total_class[class_idx]:\n",
    "                        if i[feature] == test_x[feature]:\n",
    "                            count += 1\n",
    "                    print(feature,(count+1)/(len(total_class[class_idx])+2))\n",
    "                    p_y = p_y * (count+1)/(len(total_class[class_idx])+2)\n",
    "                else: # continuous\n",
    "                    continuous_list = []\n",
    "                    for i in total_class[class_idx]:\n",
    "                        continuous_list.append(i[feature])\n",
    "                    avg = sum(continuous_list)/len(continuous_list)\n",
    "                    var = np.var(continuous_list)\n",
    "                    print(feature,self.normal_pdf(avg,var,test_x[feature]))\n",
    "                    p_y = p_y * self.normal_pdf(avg,var,test_x[feature])\n",
    "            class_probability[class_idx] = p_y\n",
    "        return class_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_predictor = NaiveBayes(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1478102189781022\n",
      "1 0.14990859232175502\n",
      "2 0.027022744380896704\n",
      "3 0.29139931447447853\n",
      "4 0.4459566065935878\n",
      "5 0.007830412140269565\n",
      "0 0.39710144927536234\n",
      "1 0.6802325581395349\n",
      "2 0.024939428202702174\n",
      "3 0.4275361270460614\n",
      "4 0.4315675017672968\n",
      "5 0.005984177238311291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.743683030522327e-07, 2.867965121877786e-06]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_predictor.predict([1.0, 1.0, 35.0, 1.0, 0.0, 53.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x7fd90b7f5d30>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in train_y:\n",
    "    count += i[0]\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
