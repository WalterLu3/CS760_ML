{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_label(data):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in data:\n",
    "        train_x.append(i[1:])\n",
    "        train_y.append([i[0]])\n",
    "        \n",
    "    return train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    answer = copy.deepcopy(x)\n",
    "    for i in range(len(x)):\n",
    "        if normalized_avg[i] != 0:\n",
    "            answer[i] = answer[i]/normalized_avg[i]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titanic_data.csv','r') as file:\n",
    "    temp = csv.reader(file)\n",
    "    data = list(temp)\n",
    "\n",
    "header = data[0]\n",
    "data = data[1:]\n",
    "for i in range(len(data)):\n",
    "    row_len = len(data[0])\n",
    "    for j in range(row_len):\n",
    "        data[i][j] = float(data[i][j])\n",
    "    \n",
    "train_x, train_y = split_train_label(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived',\n",
       " 'Pclass',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'Siblings/Spouses Aboard',\n",
       " 'Parents/Children Aboard',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "normalized_avg = []\n",
    "for i in range(len(header[1:])):\n",
    "    total = 0\n",
    "    avg = 0\n",
    "    if header[1:][i] not in ['Sex']:\n",
    "        for j in train_x:\n",
    "            total += j[i]  \n",
    "        avg = total/len(train_x)      \n",
    "        for j in range(len(train_x)):\n",
    "            train_x[j][i] = train_x[j][i]/avg\n",
    "    normalized_avg.append(avg) \n",
    "normalized_avg.append(0) # intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each x data is a row vector. y is a column vector. Need header to do normalization\n",
    "\n",
    "class logistic_titanic:\n",
    "    def __init__(self, gradientRate= 3/4, max_iter = 50000, abstol = 1e-5, add_intercept = True):\n",
    "        self.max_iter =  max_iter\n",
    "        self.abstol = abstol\n",
    "        #self.reltol = reltol\n",
    "        self.add_intercept = add_intercept\n",
    "        self.gradientRate = gradientRate\n",
    "        self.likelihoodScore = None\n",
    "        \n",
    "    def likelihood_score(self):\n",
    "        likelihood = 0\n",
    "        for i in range(len(self.training_y)):\n",
    "            temp = 0\n",
    "            x = np.array([self.training_x[i]]).T\n",
    "            temp += self.training_y[i]*math.log(1/(1+ (math.exp((-np.dot(self.theta.T,x))))))\n",
    "            temp += (1-self.training_y[i])*math.log((1/(1+ (math.exp((np.dot(self.theta.T,x)))))))\n",
    "            likelihood += temp\n",
    "        self.likelihoodScore = likelihood\n",
    "        return likelihood\n",
    "    def gradient(self):\n",
    "        gradient = np.zeros((len(self.training_x[0]),1))\n",
    "        for i in range(len(self.training_y)):\n",
    "            x = np.array([self.training_x[i]]).T\n",
    "            temp = self.training_y[i] - (1/(1+ (math.exp((-np.dot(self.theta.T,x))))))\n",
    "            gradient = gradient + temp*x\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    def logistic_predict(self):\n",
    "        answer = []\n",
    "        for i in range(len(self.training_y)):\n",
    "            temp = 0\n",
    "            temp_x = np.array([self.training_x[i]]).T\n",
    "            temp = 1/(1+math.exp(-np.dot(self.theta.T,temp_x)))\n",
    "            if temp > 1/2:\n",
    "                answer.append(1)\n",
    "            else:\n",
    "                answer.append(0)\n",
    "        return answer\n",
    "    \n",
    "    def predict(self,x):##prediction one data\n",
    "        temp_x = copy.deepcopy(x)\n",
    "        if self. add_intercept == True:\n",
    "            temp_x.append(1)\n",
    "        temp_x = np.array([temp_x]).T\n",
    "        odds = np.dot(self.theta.T,temp_x)\n",
    "        probability = 1/(1+math.exp(-np.dot(self.theta.T,temp_x)))\n",
    "        if probability > 1/2:\n",
    "            return 1, probability, odds\n",
    "        else:\n",
    "            return 0, probability, odds\n",
    "        \n",
    "    def hessian(self):\n",
    "        hessian = []\n",
    "        temp = [0] * len(self.training_x[0])\n",
    "        for i in range(len(self.training_x[0])):\n",
    "            hessian.append(temp)\n",
    "            \n",
    "        hessian = np.array(hessian)\n",
    "        for i in range(len(self.training_y)):\n",
    "            temp = 0\n",
    "            x = np.array([self.training_x[i]]).T\n",
    "            temp = math.exp((-np.dot(self.theta.T,x)))/((1+math.exp((-np.dot(self.theta.T,x))))**2)\n",
    "            temp = temp * np.dot(x,x.T)\n",
    "            hessian = hessian + temp\n",
    "        \n",
    "        return hessian\n",
    "    def fit(self,x,y): \n",
    "        ## deep copy data\n",
    "        self.training_x = np.array(copy.deepcopy(x))\n",
    "        self.training_y = np.array(copy.deepcopy(y))\n",
    "        \n",
    "        ## add intercept\n",
    "        data_num = len(self.training_x)\n",
    "        if self. add_intercept == True:\n",
    "            temp = []\n",
    "            for i in range(data_num):\n",
    "                temp.append([1])\n",
    "            self.training_x = np.append(self.training_x,temp,axis = 1)\n",
    "\n",
    "        ## initialize theta      \n",
    "        theta = []\n",
    "        \n",
    "        for i in range(len(self.training_x[0])):\n",
    "            theta.append([1])\n",
    "        \n",
    "        self.theta = np.array(theta)\n",
    "            \n",
    "        \n",
    "        ## start training\n",
    "        last_likelihood = float('-inf') \n",
    "        parameter_rate = 1/20\n",
    "        for i in range(self.max_iter):\n",
    "            if i % 50 == 0:\n",
    "                parameter_rate = parameter_rate*self.gradientRate\n",
    "            current_likelihood = self.likelihood_score()\n",
    "            if abs(current_likelihood - last_likelihood) <= self.abstol:\n",
    "                break\n",
    "            last_likelihood = current_likelihood\n",
    "            gradient_val = self.gradient()\n",
    "            self.theta = self.theta + parameter_rate*gradient_val\n",
    "            \n",
    "        return(self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =   logistic_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  59.22251105308533\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "theta = a.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('time = ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-399.89523993])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.likelihoodScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_hessian = a.hessian() \n",
    "\n",
    "fisher_inv = np.linalg.inv(current_hessian)\n",
    "\n",
    "x_my = normalize([2,0,25,0,0,50,1])\n",
    "x_my = np.array([x_my]).T\n",
    "w_variance = np.dot(x_my.T,np.dot(fisher_inv,x_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.09777457],\n",
       "       [ 2.95734936],\n",
       "       [-2.070699  ],\n",
       "       [-0.25917329],\n",
       "       [-0.03399745],\n",
       "       [-0.03815405],\n",
       "       [ 4.77374765]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14449655]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_variance**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_my = normalize([2,0,25,0,0,50,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.867481662591687, 0, 0.8482787878277828, 0.0, 0.0, 1.5477278958396383, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.355126805595913 [[-0.59657878]]\n"
     ]
    }
   ],
   "source": [
    "prediction, probability ,odds = a.predict([0.867481662591687, 0, 0.8482787878277828, 0.0, 0.0, 1.5477278958396383])\n",
    "print(prediction, probability, odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.879792]]), array([[-0.31336555]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[odds -(1.96*w_variance**(1/2)) , odds +(1.96*w_variance**(1/2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature 1 : Pclass\n",
      "    Chisquare score [118.68092055]\n",
      "    P-value =  [1.] > 95% Therefore, feature 1 is significant.\n",
      "----------------------------------------\n",
      "For feature 2 : Sex\n",
      "    Chisquare score [183.23195285]\n",
      "    P-value =  [1.] > 95% Therefore, feature 2 is significant.\n",
      "----------------------------------------\n",
      "For feature 3 : Age\n",
      "    Chisquare score [64.03212709]\n",
      "    P-value =  [1.] > 95% Therefore, feature 3 is significant.\n",
      "----------------------------------------\n",
      "For feature 4 : Siblings/Spouses Aboard\n",
      "    Chisquare score [16.50584764]\n",
      "    P-value =  [0.9999515] > 95% Therefore, feature 4 is significant.\n",
      "----------------------------------------\n",
      "For feature 5 : Parents/Children Aboard\n",
      "    Chisquare score [0.46983439]\n",
      "    P-value =  [0.50693663] < 95% Therefore, feature 5 is not significant.\n",
      "----------------------------------------\n",
      "For feature 6 : Fare\n",
      "    Chisquare score [0.28166237]\n",
      "    P-value =  [0.40438629] < 95% Therefore, feature 6 is not significant.\n",
      "----------------------------------------\n",
      "intercept\n",
      "    Chisquare score [71.63897576]\n",
      "    P-value =  [1.] > 95% Therefore, feature 7 is significant.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(theta)):\n",
    "    if i <=5 :\n",
    "        print(\"For feature\", i+1, \":\", header[i+1])\n",
    "    else:\n",
    "        print(\"intercept\")\n",
    "    score = (theta[i]**2)/fisher_inv[i][i] \n",
    "    print(\"    Chisquare score\", (theta[i]**2)/fisher_inv[i][i]  )\n",
    "    test = stats.chi2.cdf(score, 1, loc=0, scale=1)\n",
    "    if stats.chi2.cdf(score, 1, loc=0, scale=1) > 0.95:\n",
    "        print(\"    P-value = \",test, \"> 95%\", \"Therefore, feature\" ,i+1 ,\"is significant.\")\n",
    "    else:\n",
    "        print(\"    P-value = \",test, \"< 95%\", \"Therefore, feature\" ,i+1 ,\"is not significant.\")\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
