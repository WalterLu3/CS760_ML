{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_label(data):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in data:\n",
    "        train_x.append(i[1:])\n",
    "        train_y.append([i[0]])\n",
    "        \n",
    "    return train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titanic_data.csv','r') as file:\n",
    "    temp = csv.reader(file)\n",
    "    data = list(temp)\n",
    "\n",
    "header = data[0]\n",
    "data = data[1:]\n",
    "for i in range(len(data)):\n",
    "    row_len = len(data[0])\n",
    "    for j in range(row_len):\n",
    "        data[i][j] = float(data[i][j])\n",
    "    \n",
    "train_x, train_y = split_train_label(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived',\n",
       " 'Pclass',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'Siblings/Spouses Aboard',\n",
       " 'Parents/Children Aboard',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "for i in range(len(header[1:])):\n",
    "    total = 0\n",
    "    avg = 0\n",
    "    if header[1:][i] not in ['Sex','Pclass']:\n",
    "        for j in train_x:\n",
    "            total += j[i]  \n",
    "        avg = total/len(train_x)      \n",
    "        for j in range(len(train_x)):\n",
    "            train_x[j][i] = train_x[j][i]/avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoding class\n",
    "\n",
    "total_data = []\n",
    "for i in train_x:\n",
    "    temp = []\n",
    "    if i[0] == 1:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "    if i[0] == 2:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "    if i[0] == 3:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "    temp = temp + i[1:]\n",
    "    total_data.append(temp)\n",
    "train_x = total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each x data is a row vector. y is a column vector. Need header to do normalization\n",
    "\n",
    "class logistic_titanic:\n",
    "    def __init__(self, gradientRate= 3/4, max_iter = 1000, abstol = 1e-3, add_intercept = True):\n",
    "        self.max_iter =  max_iter\n",
    "        self.abstol = abstol\n",
    "        #self.reltol = reltol\n",
    "        self.add_intercept = add_intercept\n",
    "        self.gradientRate = gradientRate\n",
    "        self.likelihoodScore = None\n",
    "        \n",
    "    def likelihood_score(self):\n",
    "        likelihood = 0\n",
    "        for i in range(len(self.training_y)):\n",
    "            temp = 0\n",
    "            x = np.array([self.training_x[i]]).T\n",
    "            temp += self.training_y[i]*math.log(1/(1+ (math.exp((-np.dot(self.theta.T,x))))))\n",
    "            temp += (1-self.training_y[i])*math.log((1/(1+ (math.exp((np.dot(self.theta.T,x)))))))\n",
    "            likelihood += temp\n",
    "        self.likelihoodScore = likelihood\n",
    "        return likelihood\n",
    "    def gradient(self):\n",
    "        gradient = np.zeros((len(self.training_x[0]),1))\n",
    "        for i in range(len(self.training_y)):\n",
    "            x = np.array([self.training_x[i]]).T\n",
    "            temp = self.training_y[i] - (1/(1+ (math.exp((-np.dot(self.theta.T,x))))))\n",
    "            gradient = gradient + temp*x\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    def logistic_predict(self):\n",
    "        answer = []\n",
    "        for i in range(len(self.training_y)):\n",
    "            temp = 0\n",
    "            temp_x = np.array([self.training_x[i]]).T\n",
    "            temp = 1/(1+math.exp(-np.dot(self.theta.T,temp_x)))\n",
    "            if temp > 1/2:\n",
    "                answer.append(1)\n",
    "            else:\n",
    "                answer.append(0)\n",
    "        return answer\n",
    "    \n",
    "    def predict(self,x):##prediction one data\n",
    "        temp_x = copy.deepcopy(x)\n",
    "        if self. add_intercept == True:\n",
    "            temp_x.append(1)\n",
    "        temp_x = np.array([temp_x]).T\n",
    "        \n",
    "        temp = 1/(1+math.exp(-np.dot(self.theta.T,temp_x)))\n",
    "        if temp > 1/2:\n",
    "            return 1, temp\n",
    "        else:\n",
    "            return 0, temp\n",
    "        \n",
    "    def hessian(self):\n",
    "        hessian = []\n",
    "        temp = [0] * len(self.training_x[0])\n",
    "        for i in range(len(self.training_x[0])):\n",
    "            hessian.append(temp)\n",
    "            \n",
    "        hessian = np.array(hessian)\n",
    "        for i in range(len(self.training_y)):\n",
    "            temp = 0\n",
    "            x = np.array([self.training_x[i]]).T\n",
    "            temp = math.exp((-np.dot(self.theta.T,x)))/((1+math.exp((-np.dot(self.theta.T,x))))**2)\n",
    "            temp = temp * np.dot(x,x.T)\n",
    "            hessian = hessian + temp\n",
    "        \n",
    "        return hessian\n",
    "    def fit(self,x,y): \n",
    "        ## deep copy data\n",
    "        self.training_x = np.array(copy.deepcopy(x))\n",
    "        self.training_y = np.array(copy.deepcopy(y))\n",
    "        \n",
    "        ## add intercept\n",
    "        data_num = len(self.training_x)\n",
    "        if self. add_intercept == True:\n",
    "            temp = []\n",
    "            for i in range(data_num):\n",
    "                temp.append([1])\n",
    "            self.training_x = np.append(self.training_x,temp,axis = 1)\n",
    "\n",
    "        ## initialize theta      \n",
    "        theta = []\n",
    "        \n",
    "        for i in range(len(self.training_x[0])):\n",
    "            theta.append([1])\n",
    "        \n",
    "        self.theta = np.array(theta)\n",
    "            \n",
    "        \n",
    "        ## start training\n",
    "        last_likelihood = float('-inf') \n",
    "        parameter_rate = 1/20\n",
    "        for i in range(self.max_iter):\n",
    "            if i % 50 == 0:\n",
    "                parameter_rate = parameter_rate*self.gradientRate\n",
    "            current_likelihood = self.likelihood_score()\n",
    "            if abs(current_likelihood - last_likelihood) <= self.abstol:\n",
    "                break\n",
    "            last_likelihood = current_likelihood\n",
    "            gradient_val = self.gradient()\n",
    "            self.theta = self.theta + parameter_rate*gradient_val\n",
    "            \n",
    "        return(self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =   logistic_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  19.7120578289032\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "theta = a.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('time = ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_hessian = a.hessian() \n",
    "\n",
    "fisher = np.linalg.inv(current_hessian)/len(train_x)\n",
    "\n",
    "x_my = np.array([[0,1,0,0,25,0,0,50,1]]).T\n",
    "w_variance = np.dot(x_my.T,np.dot(fisher,x_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction, odds = a.predict([0,1,0,0,25,0,0,50])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12205141649.06177\n",
      "12205141649.061646\n",
      "12205141649.061592\n",
      "4.591772226672494e-05\n",
      "6.0937098097135744e-05\n",
      "3.886509845182897e-06\n",
      "2.370755587569964e-06\n",
      "6.992079378802705e-06\n",
      "12205141649.06141\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(fisher[i][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature 1  :\n",
      "    Chisquare score [2.66124895e-10]\n",
      "    P-value =  [1.3016158e-05] < 95% Therefore, feature 1 is not significant.\n",
      "----------------------------------------\n",
      "For feature 2  :\n",
      "    Chisquare score [2.64299876e-11]\n",
      "    P-value =  [4.1019328e-06] < 95% Therefore, feature 2 is not significant.\n",
      "----------------------------------------\n",
      "For feature 3  :\n",
      "    Chisquare score [3.40895349e-11]\n",
      "    P-value =  [4.65854826e-06] < 95% Therefore, feature 3 is not significant.\n",
      "----------------------------------------\n",
      "For feature 4  :\n",
      "    Chisquare score [167026.22901181]\n",
      "    P-value =  [1.] > 95% Therefore, feature 4 is significant.\n",
      "----------------------------------------\n",
      "For feature 5  :\n",
      "    Chisquare score [30900.58985649]\n",
      "    P-value =  [1.] > 95% Therefore, feature 5 is significant.\n",
      "----------------------------------------\n",
      "For feature 6  :\n",
      "    Chisquare score [12149.26664875]\n",
      "    P-value =  [1.] > 95% Therefore, feature 6 is significant.\n",
      "----------------------------------------\n",
      "For feature 7  :\n",
      "    Chisquare score [707.10503867]\n",
      "    P-value =  [1.] > 95% Therefore, feature 7 is significant.\n",
      "----------------------------------------\n",
      "For feature 8  :\n",
      "    Chisquare score [911.18190862]\n",
      "    P-value =  [1.] > 95% Therefore, feature 8 is significant.\n",
      "----------------------------------------\n",
      "For feature 9  :\n",
      "    Chisquare score [6.1882233e-12]\n",
      "    P-value =  [1.98482879e-06] < 95% Therefore, feature 9 is not significant.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(theta)):\n",
    "    print(\"For feature\", i+1, \" :\")\n",
    "    score = (theta[i]**2)/fisher[i][i] \n",
    "    print(\"    Chisquare score\", (theta[i]**2)/fisher[i][i]  )\n",
    "    test = stats.chi2.cdf(score, 1, loc=0, scale=1)\n",
    "    if stats.chi2.cdf(score, 1, loc=0, scale=1) > 0.95:\n",
    "        print(\"    P-value = \",test, \"> 95%\", \"Therefore, feature\" ,i+1 ,\"is significant.\")\n",
    "    else:\n",
    "        print(\"    P-value = \",test, \"< 95%\", \"Therefore, feature\" ,i+1 ,\"is not significant.\")\n",
    "    print('----------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
